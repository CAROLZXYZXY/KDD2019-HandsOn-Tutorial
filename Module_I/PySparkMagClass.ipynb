{"cells":[{"cell_type":"code","source":["#\n# AzureStorageAccess class to access Azure Storage streams\n#\n#   Parameters:\n#     container: container name in Azure Storage (AS) account\n#     account: Azure Storage (AS) account name\n#     sas: complete 'Blob service SAS URL' of the shared access signature (sas) for the container\n#     key: access key for the container, if sas is specified, key is ignored\n#\n#   Note:\n#     you need to provide value for either sas or key\n#\nclass AzureStorageAccess:\n  # constructor\n  def __init__(self, container, account, sas='', key=''):\n\n    if container == '':\n      raise ValueError('container should not be empty')\n    \n    if account == '':\n      raise ValueError('account should not be empty')\n    \n    if sas == '' and key == '' :\n      raise ValueError('provide value for either sas or key')\n    \n    self.container = container\n    self.account = account\n\n    # Set up an account access key or a SAS for the container\n    # Once an account access key or a SAS is set up in your notebook, you can use standard Spark and Databricks APIs to read from the storage account\n    # Use SAS first then account access key\n    if sas != '':\n      spark.conf.set('fs.azure.sas.%s.%s.blob.core.windows.net' % (container, account), sas)\n    else :\n      spark.conf.set('fs.azure.account.key.%s.blob.core.windows.net' % account, key)\n\n  def getFullpath(self, path):\n    return 'wasbs://%s@%s.blob.core.windows.net/%s' % (self.container, self.account, path)"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":["**MicrosoftAcademicGraph** class to access MAG streams"],"metadata":{}},{"cell_type":"code","source":["#\n# MicrosoftAcademicGraph class to access MAG streams\n#\n#   Parameters:\n#     container: container name in Azure Storage (AS) account for the MAG dataset. Usually in forms of mag-yyyy-mm-dd\n#     account: Azure Storage (AS) account containing MAG dataset\n#     sas: complete 'Blob service SAS URL' of the shared access signature (sas) for the container\n#     key: access key for the container, if sas is specified, key is ignored\n#\n#   Note:\n#     you need to provide value for either sas or key\n#     MAG streams do not have header\n#\nfrom pyspark.sql.types import *\n\nclass MicrosoftAcademicGraph(AzureStorageAccess):\n  # constructor\n  def __init__(self, container, account, sas='', key=''):\n    AzureStorageAccess.__init__(self, container, account, sas, key) \n\n  # return stream path\n  def getFullpath(self, streamName):\n    return AzureStorageAccess.getFullpath(self, self.streams[streamName][0])\n\n  # return stream header\n  def getHeader(self, streamName):\n    return self.streams[streamName][1]\n\n  datatypedict = {\n    'int' : IntegerType(),\n    'uint' : IntegerType(),\n    'long' : LongType(),\n    'ulong' : LongType(),\n    'float' : FloatType(),\n    'string' : StringType(),\n    'DateTime' : DateType(),\n  }\n\n  # return stream schema\n  def getSchema(self, streamName):\n    schema = StructType()\n    for field in self.streams[streamName][1]:\n      fieldname, fieldtype = field.split(':')\n      nullable = fieldtype.endswith('?')\n      if nullable:\n        fieldtype = fieldtype[:-1]\n      schema.add(StructField(fieldname, self.datatypedict[fieldtype], nullable))\n    return schema\n\n  # return stream dataframe\n  def getDataframe(self, streamName):\n    return spark.read.format('csv').options(header='false', delimiter='\\t').schema(self.getSchema(streamName)).load(self.getFullpath(streamName))\n\n  # define stream dictionary\n  streams = {\n    'Affiliations' : ('mag/Affiliations.txt', ['AffiliationId:long', 'Rank:uint', 'NormalizedName:string', 'DisplayName:string', 'GridId:string', 'OfficialPage:string', 'WikiPage:string', 'PaperCount:long', 'CitationCount:long', 'Latitude:float?', 'Longitude:float?', 'CreatedDate:DateTime']),\n    'Authors' : ('mag/Authors.txt', ['AuthorId:long', 'Rank:uint', 'NormalizedName:string', 'DisplayName:string', 'LastKnownAffiliationId:long?', 'PaperCount:long', 'CitationCount:long', 'CreatedDate:DateTime']),\n    'ConferenceInstances' : ('mag/ConferenceInstances.txt', ['ConferenceInstanceId:long', 'NormalizedName:string', 'DisplayName:string', 'ConferenceSeriesId:long', 'Location:string', 'OfficialUrl:string', 'StartDate:DateTime?', 'EndDate:DateTime?', 'AbstractRegistrationDate:DateTime?', 'SubmissionDeadlineDate:DateTime?', 'NotificationDueDate:DateTime?', 'FinalVersionDueDate:DateTime?', 'PaperCount:long', 'CitationCount:long', 'Latitude:float?', 'Longitude:float?', 'CreatedDate:DateTime']),\n    'ConferenceSeries' : ('mag/ConferenceSeries.txt', ['ConferenceSeriesId:long', 'Rank:uint', 'NormalizedName:string', 'DisplayName:string', 'PaperCount:long', 'CitationCount:long', 'CreatedDate:DateTime']),\n    'EntityRelatedEntities' : ('advanced/EntityRelatedEntities.txt', ['EntityId:long', 'EntityType:string', 'RelatedEntityId:long', 'RelatedEntityType:string', 'RelatedType:int', 'Score:float']),\n    'FieldOfStudyChildren' : ('advanced/FieldOfStudyChildren.txt', ['FieldOfStudyId:long', 'ChildFieldOfStudyId:long']),\n    'FieldsOfStudy' : ('advanced/FieldsOfStudy.txt', ['FieldOfStudyId:long', 'Rank:uint', 'NormalizedName:string', 'DisplayName:string', 'MainType:string', 'Level:int', 'PaperCount:long', 'CitationCount:long', 'CreatedDate:DateTime']),\n    'Journals' : ('mag/Journals.txt', ['JournalId:long', 'Rank:uint', 'NormalizedName:string', 'DisplayName:string', 'Issn:string', 'Publisher:string', 'Webpage:string', 'PaperCount:long', 'CitationCount:long', 'CreatedDate:DateTime']),\n    'PaperAbstractsInvertedIndex' : ('nlp/PaperAbstractsInvertedIndex.txt', ['PaperId:long', 'IndexedAbstract:string']),\n    'PaperAuthorAffiliations' : ('mag/PaperAuthorAffiliations.txt', ['PaperId:long', 'AuthorId:long', 'AffiliationId:long?', 'AuthorSequenceNumber:uint', 'OriginalAuthor:string', 'OriginalAffiliation:string']),\n    'PaperCitationContexts' : ('nlp/PaperCitationContexts.txt', ['PaperId:long', 'PaperReferenceId:long', 'CitationContext:string']),\n    'PaperFieldsOfStudy' : ('advanced/PaperFieldsOfStudy.txt', ['PaperId:long', 'FieldOfStudyId:long', 'Score:float']),\n    'PaperLanguages' : ('nlp/PaperLanguages.txt', ['PaperId:long', 'LanguageCode:string']),\n    'PaperRecommendations' : ('advanced/PaperRecommendations.txt', ['PaperId:long', 'RecommendedPaperId:long', 'Score:float']),\n    'PaperReferences' : ('mag/PaperReferences.txt', ['PaperId:long', 'PaperReferenceId:long']),\n    'PaperResources' : ('mag/PaperResources.txt', ['PaperId:long', 'ResourceType:int', 'ResourceUrl:string', 'SourceUrl:string', 'RelationshipType:int']),\n    'PaperUrls' : ('mag/PaperUrls.txt', ['PaperId:long', 'SourceType:int?', 'SourceUrl:string']),\n    'Papers' : ('mag/Papers.txt', ['PaperId:long', 'Rank:uint', 'Doi:string', 'DocType:string', 'PaperTitle:string', 'OriginalTitle:string', 'BookTitle:string', 'Year:int?', 'Date:DateTime?', 'Publisher:string', 'JournalId:long?', 'ConferenceSeriesId:long?', 'ConferenceInstanceId:long?', 'Volume:string', 'Issue:string', 'FirstPage:string', 'LastPage:string', 'ReferenceCount:long', 'CitationCount:long', 'EstimatedCitation:long', 'OriginalVenue:string', 'CreatedDate:DateTime']),\n    'RelatedFieldOfStudy' : ('advanced/RelatedFieldOfStudy.txt', ['FieldOfStudyId1:long', 'Type1:string', 'FieldOfStudyId2:long', 'Type2:string', 'Rank:float']),\n  }"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["**AzureStorageUtil** class to access Azure Storage streams"],"metadata":{}},{"cell_type":"code","source":["#\n# AzureStorageUtil class to access Azure Storage streams\n#\n#   Parameters:\n#     container: container name in Azure Storage (AS) account for input/output streams in PySpark notebook\n#     account: Azure Storage (AS) account\n#     sas: complete 'Blob service SAS URL' of the shared access signature (sas) for the container\n#     key: access key for the container, if sas is specified, key is ignored\n#\n#   Note:\n#     you need to provide value for either sas or key\n#     streams contain headers\n#\nclass AzureStorageUtil(AzureStorageAccess):\n  # constructor\n  def __init__(self, container, account, sas='', key=''):\n    AzureStorageAccess.__init__(self, container, account, sas, key) \n\n  def load(self, path):\n    _path = self.getFullpath(path)\n    print('laoding from ' + _path)\n    return spark.read.format('csv').options(header='true', inferSchema='true').load(_path)\n\n  def save(self, df, path, coalesce=False):\n    _path = self.getFullpath(path)\n    print('saving to ' + _path)\n    if coalesce:\n      df.coalesce(1).write.mode('overwrite').format('csv').option('header','true').save(_path)\n    else :\n      df.write.mode('overwrite').format('csv').option('header','true').save(_path)"],"metadata":{},"outputs":[],"execution_count":5}],"metadata":{"name":"PySparkMagClass","notebookId":1805405653898127},"nbformat":4,"nbformat_minor":0}
