{"cells":[{"cell_type":"code","source":["from pyspark.sql.types import *\nfrom pyspark.sql import functions as F\nimport base64\nimport array"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["# s is a base64 encoded float[] with first element being the magnitude\ndef Base64ToFloatArray(s):\n  arr = array.array('f', base64.b64decode(s))\n  return (arr[0], arr[1:])\n\ndef cosineSimilarity(s1, s2):\n  (m1, v1) = Base64ToFloatArray(s1)\n  (m2, v2) = Base64ToFloatArray(s2)\n  if (m1 == 0) or (m2 == 0):\n    return 0\n  else :\n    return sum(x*y for x,y in zip(v1, v2))/(m1 * m2)\n\n# Register udf functions so that it could be used in dataframe\n#\n# Perform same computation as cosineSimilarity()\n#\n@F.udf(\"float\")\ndef udfCosineSimilarity(s1, s2):\n  return cosineSimilarity(s1, s2)"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":["**NetworkSimilarity** class to compute Network Similarity"],"metadata":{}},{"cell_type":"code","source":["#   Parameters:\n#     resource: resource stream path\n#     container: container name in Azure Storage (AS) account\n#     account: Azure Storage (AS) account\n#     sas: complete 'Blob service SAS URL' of the shared access signature (sas) for the container\n#     key: access key for the container, if sas is specified, key is ignored\n#\n#   Note:\n#     resource does not have header\n#     you need to provide value for either sas or key\n#\nclass NetworkSimilarity(AzureStorageAccess):\n  # constructor\n  def __init__(self, resource, container, account, sas='', key=''):\n    AzureStorageAccess.__init__(self, container, account, sas, key)\n    schema = StructType()\n    schema.add(StructField('EntityId', LongType(), False))\n    schema.add(StructField('EntityType', StringType(), False))\n    schema.add(StructField('Data', StringType(), False))\n    self.df = spark.read.format('csv').options(header='false', delimiter='\\t').schema(schema).load(self.getFullpath(resource))\n\n  def getDataframe(self):\n    return self.df\n  \n  def raiseErrorIfNotFound(self, row, e):\n    if row is None:\n      raise KeyError('entity ' + str(e) + ' not found')\n\n  def getSimilarity(self, e1, e2):\n    df = self.df\n    row1 = df.where(df.EntityId == e1).first()\n    self.raiseErrorIfNotFound(row1, e1)\n    row2 = df.where(df.EntityId == e2).first()\n    self.raiseErrorIfNotFound(row2, e2)\n    return cosineSimilarity(row1.Data, row2.Data)\n\n  def getTopEntities(self, e, targetType = '', maxCount = 20, minScore = 0.0):\n    df1 = self.df\n    row1 = df1.where(df1.EntityId == e).first()\n    self.raiseErrorIfNotFound(row1, e)\n\n    if targetType == '':\n      df2 = df1.where(df1.EntityId != e)\n    else :\n      df2 = df1.where((df1.EntityId != e) & (df1.EntityType == targetType))\n\n    df3 = df2.select(df2.EntityId, df2.EntityType, udfCosineSimilarity(F.lit(row1.Data), df2.Data).alias('score'))\n    return df3.where(df3.score >= minScore).orderBy(df3.score.desc()).limit(maxCount)"],"metadata":{},"outputs":[],"execution_count":4}],"metadata":{"name":"PySparkNetworkSimilarityClass","notebookId":1805405653898160},"nbformat":4,"nbformat_minor":0}
